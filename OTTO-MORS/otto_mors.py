# -*- coding: utf-8 -*-
"""OTTO-MORS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XDxqcjq_VjMPRz-P30LKX9wCHJWiAUKR

# OTTO â€“ Multi-Objective Recommender System

## Goal of the Competition
The goal of this competition is to predict e-commerce clicks, cart additions, and orders. You'll build a multi-objective recommender system based on previous events in a user session.

Your work will help improve the shopping experience for everyone involved. Customers will receive more tailored recommendations while online retailers may increase their sales.

## Context
Online shoppers have their pick of millions of products from large retailers. While such variety may be impressive, having so many options to explore can be overwhelming, resulting in shoppers leaving with empty carts. This neither benefits shoppers seeking to make a purchase nor retailers that missed out on sales. This is one reason online retailers rely on recommender systems to guide shoppers to products that best match their interests and motivations. Using data science to enhance retailers' ability to predict which products each customer actually wants to see, add to their cart, and order at any given moment of their visit in real-time could improve your customer experience the next time you shop online with your favorite retailer.

Current recommender systems consist of various models with different approaches, ranging from simple matrix factorization to a transformer-type deep neural network. However, no single model exists that can simultaneously optimize multiple objectives. In this competition, youâ€™ll build a single entry to predict click-through, add-to-cart, and conversion rates based on previous same-session events.

With more than 10 million products from over 19,000 brands, OTTO is the largest German online shop. OTTO is a member of the Hamburg-based, multi-national Otto Group, which also subsidizes Crate & Barrel (USA) and 3 Suisses (France).

Your work will help online retailers select more relevant items from a vast range to recommend to their customers based on their real-time behavior. Improving recommendations will ensure navigating through seemingly endless options is more effortless and engaging for shoppers.

# Imports ðŸ“¥
"""

import pandas as pd
import seaborn as sns
import numpy as np
import multiprocessing
import polars as pl
from gensim.test.utils import common_texts
from gensim.models import Word2Vec
import os
from annoy import AnnoyIndex
import collections

"""# Constants ðŸ“‹"""

# PATH = "\input\otto-full-optimized-memory-footprint"
PATH1 = "input"
PATH2 = "otto-full-optimized-memory-footprint"
TEST_NAME = "test.parquet"
TRAIN_NAME = "train.parquet"
TEST_PATH = os.path.join(PATH1, PATH2, TEST_NAME)
TRAIN_PATH = os.path.join(PATH1, PATH2, TRAIN_NAME)

"""# Funcions ðŸ“˜"""

def m20_mult(x, n_length):
    x = x[-20:]
    if n_length > 19:
        n_length = 19
    if len(x) >= n_length:
        y = []
        y_sum = list(np.zeros(21-len(x)))
        for i in range(n_length):
            y.append(list(index.get_nns_by_item(x[-(i+1)], 21 - len(x))[1:]))
            y_sum += y[-1]

        counter = dict(collections.Counter(y_sum))
        res = sorted(list(set(y_sum)), key = lambda d: counter[d], reverse=True)
    else:
        res = list(index.get_nns_by_item(x[-1], 21 - len(x))[1:])
        
    x = list(x) + list(res)[:20-len(x)]
    
    return x

"""# Data modification ðŸ“Š

Get data using *polar* and the function *read_paquet*
"""

print('Get data using *polar* and the function *read_paquet*')

train_df = pl.read_parquet(TRAIN_PATH)
test_df = pl.read_parquet(TEST_PATH)

"""Show the raw data"""

print('Show the raw data')

train_df.head()

test_df.head()

sentences_df = pl.concat([train_df, test_df]).groupby("session").agg(pl.col("aid").alias("sentence"))

sentences_df.head()

"""Modify the data to imporve the results of the model."""

print('Modify the data to imporve the results of the model.')

test_pred_df = pl.concat([test_df]).groupby("session").agg(pl.col("aid").alias("sentence"))
test_pred_df.head()

sentences_df.head()

test_pred_df = test_pred_df.to_pandas().rename(columns={'sentence':'labels'})

sentences_df_clicks = pl.concat([test_df]).filter(pl.col('type') == 0)
sentences_df_carts = pl.concat([test_df]).filter(pl.col('type') == 1)
sentences_df_orders = pl.concat([test_df]).filter(pl.col('type') == 2)

sentences_df_clicks = sentences_df_clicks.groupby('session').agg(pl.col('aid').alias('sentence'))
sentences_df_carts = sentences_df_carts.groupby('session').agg(pl.col('aid').alias('sentence'))
sentences_df_orders = sentences_df_orders.groupby('session').agg(pl.col('aid').alias('sentence'))

sentences_df_clicks = sentences_df_clicks.to_pandas().rename(columns={'sentence':'labels_clicks'})
sentences_df_carts = sentences_df_carts.to_pandas().rename(columns={'sentence':'labels_carts'})
sentences_df_orders = sentences_df_orders.to_pandas().rename(columns={'sentence':'labels_orders'})

test_pred_df = test_pred_df.merge(sentences_df_clicks, how='left', on='session') \
                           .merge(sentences_df_carts, how='left', on='session') \
                           .merge(sentences_df_orders, how='left', on='session') 
test_pred_df.head()

sentences_list = sentences_df['sentence'].to_list()

n_cores = multiprocessing.cpu_count() - 1
w2v = Word2Vec(
    sentences = sentences_list,
    vector_size = 100,
    alpha = 0.02,
    min_alpha = 0.01,
    min_count = 1,
    workers = n_cores)

"""We load the model we have downloaded to predict the results."""

print('We load the model we have downloaded to predict the results.')

w2v.save("w2vc.model")
model = Word2Vec.load("w2vc.model")

aid2idx = {aid: i for i, aid in enumerate(model.wv.index_to_key)}
index = AnnoyIndex(100, 'angular')

for aid, idx in aid2idx.items():
    index.add_item(aid, model.wv.vectors[idx])
    
index.build(50)

"""Split the labels by carts, order r clicks."""

print('Split the labels by carts, order r clicks.')

test_pred_df['labels_carts'] = test_pred_df['labels_carts'].fillna(test_pred_df['labels'])
test_pred_df['labels_orders'] = test_pred_df['labels_orders'].fillna(test_pred_df['labels'])
test_pred_df['labels_clicks'] = test_pred_df['labels_clicks'].fillna(test_pred_df['labels'])

test_pred_df['labels'] = test_pred_df.labels.apply(lambda x: list(set(x)))
test_pred_df['labels'] = test_pred_df.labels.apply(lambda x: m20_mult(x, len(x)))
test_pred_df['labels'] = test_pred_df.labels.apply(lambda x: " ".join(map(str,x)))
test_pred_df = test_pred_df.drop(['labels_clicks', 'labels_carts', 'labels_orders'], axis=1)
clicks_pred_df = test_pred_df.copy()
clicks_pred_df.session = clicks_pred_df.session.apply(lambda x: str(x) + '_clicks')
orders_pred_df = test_pred_df.copy()
orders_pred_df.session = orders_pred_df.session.apply(lambda x: str(x) + '_orders')
carts_pred_df = test_pred_df.copy()
carts_pred_df.session = carts_pred_df.session.apply(lambda x: str(x) + '_carts')

pred_df = pd.concat(
    [clicks_pred_df, orders_pred_df, carts_pred_df]
)
pred_df.columns = ['session_type', 'labels']

"""Predict the results"""

print('Predict the results')

pred_df = pred_df.sort_values(by='session_type').reset_index()
pred_df = pred_df.drop('index', axis=1)

"""## Submission ðŸ“¤"""

pred_df.to_csv("submission.csv", index=False)

